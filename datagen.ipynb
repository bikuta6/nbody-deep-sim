{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sim import NBodySimulation, generateDisk3Dv3\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 111\u001b[0m\n\u001b[1;32m    107\u001b[0m             json\u001b[38;5;241m.\u001b[39mdump(dataset, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n\u001b[0;32m--> 111\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 71\u001b[0m, in \u001b[0;36mgenerate_dataset\u001b[0;34m(n_scenes, window_size, shuffle, dir, save)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_dataset\u001b[39m(n_scenes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, window_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28mdir\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/train/\u001b[39m\u001b[38;5;124m'\u001b[39m, save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# Ensure the directory exists\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mdir\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;66;03m# the objective is to generate samples from n scenes, of 3 frames each, saving positions, velocities and accelerations, the idea is to predict acceleration from the first frame for the next 2 frames to integrate position and velocity\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     other_files \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;28mdir\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "def gen_params():\n",
    "    return {\n",
    "        'nbStars': int(np.random.randint(100, 500)),\n",
    "        'radius': float(np.random.uniform(1.0, 2.0)),\n",
    "        'Mass': float(np.random.uniform(1.0, 3.0)),\n",
    "        'zOffsetMax': float(np.random.uniform(0, 0.5)),\n",
    "        'gravityCst': 1.0,\n",
    "        'distribution': 'hernquist',\n",
    "        'offset': [float(np.random.uniform(-1, 1)), float(np.random.uniform(-1, 1)), float(np.random.uniform(-1, 1))],\n",
    "        'initial_vel': [float(np.random.uniform(-0.1, 0.1)), float(np.random.uniform(-0.1, 0.1)), float(np.random.uniform(-0.1, 0.1))],\n",
    "        'clockwise': int(np.random.choice([1, 0])),\n",
    "        'angle': [float(np.random.uniform(-1, 1)*2*np.pi), float(np.random.uniform(-1, 1)*2*np.pi), float(np.random.uniform(-1, 1)*2*np.pi)]\n",
    "    }\n",
    "\n",
    "def generate_scene_2gals():\n",
    "    params1 = gen_params()\n",
    "    params2 = gen_params()\n",
    "    print(params1)\n",
    "    print(params2)\n",
    "\n",
    "    particles1 = generateDisk3Dv3(**params1)\n",
    "    particles2 = generateDisk3Dv3(**params2)\n",
    "\n",
    "    t_end = 10.0\n",
    "    dt = 0.01\n",
    "    softening = 0.1\n",
    "    G = 1.0\n",
    "\n",
    "    particles = particles1 + particles2\n",
    "    sim = NBodySimulation(particles, G, softening, dt)\n",
    "\n",
    "    pos, vel, acc, KE, PE, _, masses, types = sim.run(t_end=t_end, save_states=True)\n",
    "    \n",
    "    # Convert all arrays to lists\n",
    "    pos = np.array(pos).transpose(2, 0, 1)\n",
    "    vel = np.array(vel).transpose(2, 0, 1)\n",
    "    acc = np.array(acc).transpose(2, 0, 1)\n",
    "    KE = KE.flatten().astype(float).tolist()  # Ensure floats\n",
    "    PE = PE.flatten().astype(float).tolist()  # Ensure floats\n",
    "    masses = masses.flatten().astype(float).tolist()  # Ensure floats\n",
    "\n",
    "\n",
    "    frames = []\n",
    "    for i in range(len(pos)):\n",
    "        frames.append({\n",
    "            'frame': int(i),  # Ensure the frame index is an int\n",
    "            'pos': pos[i].tolist(),\n",
    "            'vel': vel[i].tolist(),\n",
    "            'acc': acc[i].tolist()\n",
    "        })\n",
    "\n",
    "    final_json = {\n",
    "        'galaxy1_params': params1,\n",
    "        'galaxy2_params': params2,\n",
    "        'dt': float(dt),\n",
    "        'softening': float(softening),\n",
    "        'G': float(G),\n",
    "        't_end': float(t_end),\n",
    "        'masses': [float(m) for m in masses],\n",
    "        'types': types,\n",
    "        'KE': KE,\n",
    "        'PE': PE,\n",
    "        'frames': frames\n",
    "    }\n",
    "\n",
    "    return json.dumps(final_json, indent=4)\n",
    "\n",
    "\n",
    "def generate_dataset(n_scenes=5, window_size=3, shuffle=True, dir='/train/', save=True):\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "    \n",
    "    # the objective is to generate samples from n scenes, of 3 frames each, saving positions, velocities and accelerations, the idea is to predict acceleration from the first frame for the next 2 frames to integrate position and velocity\n",
    "    other_files = glob.glob(dir + '*.json')\n",
    "    # get the last id from the files, given the structure of the file names is train_0.json, train_1.json, etc\n",
    "    last_id = -1\n",
    "    for file in other_files:\n",
    "        last_id = max(last_id, int(file.split('_')[-1].split('.')[0]))\n",
    "\n",
    "    new_id = last_id + 1\n",
    "    name = dir + f'{dir[1:-1]}_{new_id}.json'\n",
    "    \n",
    "    dataset = []\n",
    "    for i in range(n_scenes):\n",
    "        scene = generate_scene_2gals()\n",
    "        scene = json.loads(scene)\n",
    "        frames = scene['frames']\n",
    "        masses = scene['masses']\n",
    "        for j in range(len(frames)-window_size):\n",
    "            sample = {\n",
    "                'scene': i,\n",
    "                'frame': j,\n",
    "                'masses': masses,\n",
    "                'pos': frames[j]['pos'],\n",
    "                'vel': frames[j]['vel'],\n",
    "                'acc': frames[j]['acc'],\n",
    "            }\n",
    "            for k in range(1, window_size):\n",
    "                sample['pos_next{}'.format(k)] = frames[j+k]['pos']\n",
    "                sample['vel_next{}'.format(k)] = frames[j+k]['vel']\n",
    "                sample['acc_next{}'.format(k)] = frames[j+k]['acc']\n",
    "            dataset.append(sample)\n",
    "    if shuffle:\n",
    "        np.random.shuffle(dataset)\n",
    "    if save:\n",
    "        with open(name, 'w') as f:\n",
    "            json.dump(dataset, f, indent=4)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "dataset = generate_dataset(5, 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
